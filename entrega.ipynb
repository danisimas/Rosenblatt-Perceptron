{"cells":[{"cell_type":"markdown","metadata":{"id":"rKmMxSVh4qZV"},"source":["# RNA - Atividade 2.1 - Perceptron de Rosenblatt\n","\n","Neste projeto prático, o objetivo é implementar o algoritmo de treinamento mediante Aprendizado Supervisionado do neurônio Perceptron de Rosenblatt aplicado em problemas de classificação. Para tanto, cada equipe deverá elaborar Jupyter Notebooks com o código-fonte deste algoritmo de treinamento desenvolvido na linguagem de Programação Python e fazendo uso das bibliotecas numpy, random, math e matplotlib. Em particular, a biblioteca numpy será de uso obrigatório para todas as operações de natureza matricial (multiplicação de matrizes, produto escalar, etc). Neste projeto prático, a biblioteca sci-kit learn só deve ser utilizada para o cálculo de métricas de desempenho."]},{"cell_type":"markdown","metadata":{"id":"PcBWNRZ14qZW"},"source":["## Equipe\n","\n","- Daniele Simas - 2015310060\n","- Felipe Amorim - 2115080033\n","- José Manuel - 2115080052\n","- Miguel Angelo - 2115080024"]},{"cell_type":"markdown","metadata":{"id":"ul4fYqLR4qZW"},"source":["## Importação de Bibliotecas"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":323,"status":"ok","timestamp":1716492042438,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"3uAzOvtY4qZW"},"outputs":[],"source":["import numpy as np\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from matplotlib.axes import Axes\n","from prettytable import PrettyTable\n","from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n","\n","import itertools"]},{"cell_type":"markdown","metadata":{"id":"BDwus15u4qZX"},"source":["## Funções auxiliares"]},{"cell_type":"markdown","metadata":{"id":"08pzwZi54qZX"},"source":["### Função de ativação\n","Arquivo original: `src/activation_functions.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":427,"status":"ok","timestamp":1716492043182,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"pPgR03hD4qZY"},"outputs":[],"source":["def step_function(x: float) -> int:\n","    \"\"\"\n","    Step activation function.\n","\n","    Parameters:\n","        x (float): Input value.\n","\n","    Returns:\n","        int: Output value (0 or 1).\n","    \"\"\"\n","    return 1 if x >= 0 else 0"]},{"cell_type":"markdown","metadata":{"id":"vBn00vx44qZc"},"source":["### Função para leitura dos arquivos de dados\n","Arquivo original: `src/utils.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"8z2dzaXl4qZd"},"outputs":[],"source":["def read_data(filename: str):\n","    # Read data from file\n","    data = np.fromfile(f\"./task/data/data{filename}.txt\")\n","\n","    # Separate values into (x1 x2 y) elements\n","    data = data.reshape(-1, 3)\n","\n","    # Reorganize valkues into [([x1.1,x1.2], y1), ([x2.1,x2.2], y2)]\n","    data = np.array([(row[:2], row[2]) for row in data], dtype=object)\n","\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"c_2JJ4zH4qZe"},"source":["### Função para calcular identificador da equipe\n","Arquivo original: `src/utils.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"ZsUDy79B4qZe"},"outputs":[],"source":["def identifier(values):\n","    # Pick last digit of each value\n","    last_digits = (int(value[-1]) for value in values)\n","\n","    # Sum the digits\n","    soma = sum(last_digits)\n","\n","    # Calcutate the final result\n","    result = soma % 4\n","\n","    return str(result)"]},{"cell_type":"markdown","metadata":{"id":"AQjqSHx84qZf"},"source":["### Função para dividir um vetor em duas partições\n","Arquivo original: `src/utils.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"_gi2EHgz4qZg"},"outputs":[],"source":["def train_test_split(data: np.ndarray, train_portion=0.7):\n","    # Make a copy from data\n","    copy = data.copy()\n","\n","    # Shuffle the data\n","    np.random.shuffle(copy)\n","\n","    # Calculate an edge for splitting\n","    edge = int(data.shape[0] * train_portion)\n","\n","    # Return train and test portions respectively\n","    return copy[:edge], copy[edge:]"]},{"cell_type":"markdown","metadata":{"id":"Zaf2Y2d54qZg"},"source":["### Função para criar gráfico de pontos E linha de decisão do neurônio\n","Arquivo original: `src/utils.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"B79QpB974qZg"},"outputs":[],"source":["def plot_results(x_data, y_data, weights=None, ax: Axes = None):\n","    if ax is None:\n","        _, ax = plt.subplots(figsize=(8, 8))\n","\n","    # Criar gráfico de dispersão dos pontos de entrada usando os parametros \"data\"\n","    class_0 = x_data[y_data == 0]\n","    class_1 = x_data[y_data == 1]   \n","\n","    ax.scatter(class_0[:, 1], class_0[:, 2], color=\"red\", marker=\"x\", label=\"Classe 0\")\n","    ax.scatter(class_1[:, 1], class_1[:, 2], color=\"blue\", marker=\"o\", label=\"Classe 1\")\n","\n","    # Criar gráfico de linha da reta x2 = -(w1/w2)x1 + (w0/w2) gerada pelo perceptron\n","    if weights is not None:\n","        w0, w1, w2 = weights\n","\n","        x1_min = np.min(x_data[:, 1]) - 0.5\n","        x1_max = np.max(x_data[:, 1]) + 0.5\n","        x1_values = np.linspace(x1_min, x1_max, 2)\n","\n","        x2_min = np.min(x_data[:, 2]) - 0.5\n","        x2_max = np.max(x_data[:, 2]) + 0.5\n","        ax.set_ylim(x2_min, x2_max)\n","\n","        x2_values = -(w1 / w2) * x1_values + (w0 / w2)\n","\n","        ax.plot(\n","            x1_values,\n","            x2_values,\n","            color=\"black\",\n","            linestyle=\"-\",\n","            linewidth=2,\n","            label=\"Linha de decisão\",\n","        )\n","\n","    # Adicionar títulos e legendas\n","    ax.set_title(\"Linha de Decisão e Pontos do Problema\")\n","\n","    ax.set_xlabel(\"x1\")\n","    ax.set_ylabel(\"x2\")\n","\n","    ax.grid(True)"]},{"cell_type":"markdown","metadata":{},"source":["### Função para criar o gráfico matriz confusão\n","Arquivo original: `src/utils.py`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def draw_matrix(real, predicted, title='Matriz de confusão'):\n","    cm = metrics.confusion_matrix(real, predicted)\n","\n","    plt.figure(figsize=(8, 8))\n","\n","    plt.title(title)\n","    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n","\n","    thresh = cm.max() / 2.0\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], '.2f').lstrip('0').rstrip('.00'),\n","                    horizontalalignment=\"center\",\n","                    verticalalignment=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.xlabel('Classe prevista')\n","    plt.ylabel('Classe real')\n","\n","    plt.colorbar(shrink=0.6)\n","\n","    labels = np.sort(np.unique(real))\n","    ticks = range(len(labels))\n","    plt.xticks(ticks, labels)\n","    plt.yticks(ticks, labels)\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"t72-9vqP4qZg"},"source":["### Função para execução do treinamento com todas as combinações possíveis dos parametros de entrada:\n","\n","Arquivo original: `src/_parte2.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"WirYKjTt4qZh"},"outputs":[],"source":["def train_with_parameters(perceptron, rates, ranges):\n","    results = dict()\n","\n","    for range_bounds, learning_rate in itertools.product(ranges, rates):\n","        perceptron.learning_rate = learning_rate\n","\n","        results[(learning_rate, range_bounds)] = []\n","\n","        for _ in range(10):\n","            perceptron.randomize_weights(-range_bounds, range_bounds + 0.1)\n","\n","            # Train the perceptron\n","            epochs, updates = perceptron.train()\n","\n","            # Save training results\n","            results[(learning_rate, range_bounds)].append(\n","                {\n","                    \"epoch_count\": epochs,\n","                    \"update_count\": updates,\n","                    \"final_weights\": perceptron.weights,\n","                }\n","            )\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"xQIo_qGU4qZh"},"source":["## Implementação do Perceptron\n","Arquivo original: `src/perceptron.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"gJ6rOPGT4qZh"},"outputs":[],"source":["class Perceptron:\n","    def __init__(\n","        self,\n","        data: np.ndarray,\n","        activation_function=None,\n","        bias: float = -1,\n","        learning_rate: float = 0.1,\n","    ):\n","        \"\"\"\n","        Initialize the Perceptron.\n","\n","        Parameters:\n","            data (np.ndarray): The input data as a numpy array of tuples (input, output).\n","            activation_function (function, optional): The activation function. Defaults to None.\n","            bias (float, optional): The bias value. Defaults to -1.\n","            learning_rate (float, optional): The learning rate. Defaults to 0.1.\n","        \"\"\"\n","        self.bias = bias\n","        self.learning_rate = learning_rate\n","\n","        self.activation_function = (\n","            activation_function if activation_function else step_function\n","        )\n","\n","        self._input_data = None\n","        self._output_data = None\n","        self._data = None\n","        self.data = data  # This will call the setter and initialize _input_data and _output_data\n","\n","    @property\n","    def data(self):\n","        \"\"\"\n","        Get the input and output data as a combined numpy array.\n","\n","        Returns:\n","            np.ndarray: Combined input and output data.\n","        \"\"\"\n","        return self._data\n","\n","    @data.setter\n","    def data(self, value: np.ndarray):\n","        \"\"\"\n","        Separate the input and output data into two numpy arrays.\n","        Prepends self.bias to input and sets the weight array length based on input data.\n","\n","        Parameters:\n","            value (np.ndarray): The input data as a numpy array of tuples (input, output).\n","        \"\"\"\n","        if not isinstance(value, np.ndarray):\n","            raise ValueError(\"Data must be a numpy array\")\n","\n","        if not all(len(i) == 2 for i in value):\n","            raise ValueError(\"Data must be a numpy array of tuples (input, output)\")\n","\n","        self._data = value\n","\n","        self._input_data = np.array(\n","            [np.insert(item[0], 0, self.bias) for item in value]\n","        )\n","        self._output_data = np.array([item[1] for item in value])\n","\n","        self.__init_weights()\n","\n","    def __init_weights(self):\n","        \"\"\"\n","        Initialize the weights array.\n","        \"\"\"\n","        self.weights = np.zeros(len(self._input_data[0]))\n","\n","    def randomize_weights(self, floor=-0.5, ceiling=0.5):\n","        \"\"\"\n","        Set each value of the weight array to a random number between the given interval\n","        \"\"\"\n","        self.weights = np.random.uniform(floor, ceiling, len(self.weights))\n","\n","    @property\n","    def input_data(self) -> np.ndarray:\n","        \"\"\"\n","        Get the input data.\n","\n","        Returns:\n","            np.ndarray: Input data.\n","        \"\"\"\n","        return self._input_data\n","\n","    @property\n","    def output_data(self) -> np.ndarray:\n","        \"\"\"\n","        Get the output data.\n","\n","        Returns:\n","            np.ndarray: Output data.\n","        \"\"\"\n","        return self._output_data\n","\n","    def train(self, max_epochs: int = None):\n","        \"\"\"\n","        Train the Perceptron. Stops on max_epochs or on convergence.\n","\n","        Parameters:\n","            max_epochs (int, optional): Maximum number of training epochs. Defaults to None.\n","\n","        Returns:\n","            (epoch, weight_updates): Number of epochs trained and the amount of updates applied to the weights array done.\n","        \"\"\"\n","        self.weight_updates = 0\n","        last_weight_update = 0\n","\n","        # Count the number of weight updates done in each epoch\n","        self.updates_per_epoch = []\n","\n","        # Train for at maximum \"max_epoch\" epochs\n","        if max_epochs and max_epochs > 0:\n","            for epoch in range(max_epochs):\n","                self.__run_single_epoch()\n","\n","                # No change means every value was correctly predicted and no more training is necessary\n","                if last_weight_update == self.weight_updates:\n","                    return epoch + 1, self.weight_updates\n","\n","                last_weight_update = self.weight_updates\n","            return max_epochs, self.weight_updates\n","\n","        # Train until done OR user decides to quit on multiple of 1000\n","        epoch = 0\n","        while True:\n","            self.__run_single_epoch()\n","            epoch += 1\n","\n","            if epoch % 1000 == 0:\n","                choice = input(f\"Trained for {epoch} epochs, continue? (y/n) \")\n","\n","                if choice in \"nN\":\n","                    return epoch, self.weight_updates\n","\n","            # No change means every value was correctly predicted and no more training is necessary\n","            if last_weight_update == self.weight_updates:\n","                return epoch, self.weight_updates\n","\n","            last_weight_update = self.weight_updates\n","\n","    def shuffle_train(self, max_epochs: int):\n","        \"\"\"\n","        Train the Perceptron, shuffling the training data every epoch. Stops on max_epochs or on convergence.\n","\n","        Parameters:\n","            max_epochs (int, optional): Maximum number of training epochs. Defaults to None.\n","\n","        Returns:\n","            (epoch, weight_updates): Number of epochs trained and the amount of updates applied to the weights array done.\n","        \"\"\"\n","        self.weight_updates = 0\n","        last_weight_update = 0\n","\n","        # Count the number of weight updates done in each epoch\n","        self.updates_per_epoch = []\n","\n","        # Train for at maximum \"max_epoch\" epochs\n","        for epoch in range(max_epochs):\n","            # The \"data\" setter resets the perceptron weights, so we must save them before shuffling\n","            current_weights = self.weights\n","\n","            shuffled_data = self._data.copy()\n","            np.random.shuffle(shuffled_data)\n","            self.data = shuffled_data\n","\n","            self.weights = current_weights\n","\n","            self.__run_single_epoch()\n","\n","            # No change means every value was correctly predicted and no more training is necessary\n","            if last_weight_update == self.weight_updates:\n","                return epoch + 1, self.weight_updates\n","\n","            last_weight_update = self.weight_updates\n","\n","        return max_epochs, self.weight_updates\n","\n","    def predict(self, values: np.ndarray):\n","        \"\"\"\n","        Predict the output for the given input values.\n","\n","        Parameters:\n","            values (np.ndarray): Input values.\n","\n","        Returns:\n","            Predicted output.\n","        \"\"\"\n","        u = np.dot(values, self.weights)\n","        return self.activation_function(u)\n","\n","    def __run_single_epoch(self):\n","        \"\"\"\n","        Perform a single epoch of training.\n","        \"\"\"\n","\n","        update_count = 0\n","        for input_values, output_value in zip(self._input_data, self._output_data):\n","\n","            y = self.predict(input_values)\n","\n","            if y == output_value:\n","                continue\n","\n","            error = output_value - y\n","\n","            self.weights = self.weights + self.learning_rate * error * input_values\n","            update_count += 1\n","\n","        self.weight_updates += update_count\n","        self.updates_per_epoch.append(update_count)"]},{"cell_type":"markdown","metadata":{"id":"d_b6h5qc4qZh"},"source":["### Exemplo de uso"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"I2TV9iw84qZh","outputId":"26f0a20e-fe6e-46d1-d0bc-55cbab066bfd"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    # Example data: List of tuples (input, output)\n","    example_data = [(np.array([2, 2]), 1), (np.array([4, 4]), 0)]\n","    # Convert the list of tuples to a NumPy array\n","    example_data = np.array(example_data, dtype=object)\n","\n","    # Initialize the Perceptron\n","    perceptron = Perceptron(data=example_data)\n","    perceptron.randomize_weights()\n","\n","    # Check the weights\n","    print(\"Randomized weights:\", perceptron.weights)\n","\n","    # training\n","    epochs, updates = perceptron.train()\n","\n","    # Looking at the results\n","    print(f\"Finished training in {epochs} epochs with {updates} updates!\")\n","    print(\"Final weights:\", perceptron.weights)\n","    print(\"Adjusts done in each epoch:\", perceptron.updates_per_epoch)\n"]},{"cell_type":"markdown","metadata":{"id":"8vEXobWC4qZh"},"source":["# Parte 1 - Resolvendo um problema linearmente separável\n","\n","Nesta parte, todas as equipes devem usar o arquivo `dataAll.txt` e construir o algoritmo de treinamento do neurônio perceptron para resolver o problema de classificação proposto."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716492043183,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"pzeUlvco4qZi","outputId":"3d1aaf55-af78-42ec-a45e-fb1e23f05044"},"outputs":[],"source":["data = read_data('All')\n","\n","print(\"Quantidade de pontos lidos:\", len(data))\n","print(\"Formato dos dados:\", data.shape)\n","print(\"\\nExemplos de dados:\", *[(x, y) for x,y in data[:5]], sep='\\n')"]},{"cell_type":"markdown","metadata":{"id":"UB71kEvh4qZi"},"source":["1. As equipes devem utilizar a função de ativação degrau com ϑ = 0;\n","2. O valor da taxa de aprendizado deve ser igual a η = 0,1;\n","3. O vetor inicial de pesos deve ter seus valores inicializados conforme uma variável aleatória de distribuição uniforme no intervalo, isto é, wi ∼ U (−0,5, + 0,5). O vetor inicial de pesos deve ser impresso no início da execução do algoritmo;"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716492043184,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"t8PDgCXq4qZi","outputId":"371206bb-4b85-4e2c-e4f5-34cdfcfba200"},"outputs":[],"source":["perceptron = Perceptron(data=data, activation_function=step_function, bias=-1, learning_rate=0.1)\n","\n","print('Vetor de pesos inicial: ', perceptron.weights)\n","\n","perceptron.randomize_weights(floor=-0.5, ceiling=0.501)\n","print('Vetor de pesos após a randomização: ', perceptron.weights)"]},{"cell_type":"markdown","metadata":{"id":"qCZysVx74qZj"},"source":["4. A cada época deve ser indicado o número de ajustes feitos no vetor de pesos;\n","5. O algoritmo deve executar até a convergência, isto é, até que não haja erros para todos os exemplos presentes no conjunto de treinamento;\n","6. Ao final, deve-se imprimir:\n","    - A - O número total de ajustes no vetor de pesos;\n","    - B - O número de épocas até a convergência;\n","    - C - O gráfico contendo todos os exemplos do conjunto de dados e a reta que separa as classes obtida como resultado do treinamento do neurônio Perceptron. Respeitar o esquema de cores proposto inicialmente e apresentar a solução de maneira clara neste gráfico."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716492043184,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"wDbDzNak4qZj","outputId":"2ace2c93-7d2e-4ee0-c3b0-43fafd5b04d3"},"outputs":[],"source":["epoch, updates = perceptron.train()\n","\n","print(*[f'Na epóca {index+1} foram realizados {count} ajustes.' for index, count in enumerate(perceptron.updates_per_epoch)], sep='\\n')\n","print('Treinamento finalizado!')\n","print(\"---\")\n","print('Quantidade de épocas até a convergência: ', epoch)\n","print('Quantidade de ajustes no vetor de pesos: ', updates)\n","print(\"Vetor de pesos final: \", perceptron.weights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"executionInfo":{"elapsed":695,"status":"ok","timestamp":1716492043872,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"7oY5tDUG4qZj","outputId":"2ce09afa-9be3-4454-e06b-00329f4f33be"},"outputs":[],"source":["plot_results(perceptron.input_data, perceptron.output_data, perceptron.weights)"]},{"cell_type":"markdown","metadata":{"id":"petNhYV54qZj"},"source":["# Parte 2 - Experimentação\n","\n","Nesta segunda parte, cada equipe deverá usar o seu respectivo identificador de exemplos para trabalhar com um arquivo específico."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716492043873,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"tkf2P00q4qZk","outputId":"b19da24a-08f4-4ff0-8499-45b4cfb83913"},"outputs":[],"source":["matriculas = [\"2015310060\", '2115080033', \"2115080052\", \"2115080024\"]\n","\n","team_id = identifier(matriculas)\n","\n","print(\"Identificador da equipe:\", team_id)\n","\n","data = read_data(team_id)\n","\n","print(\"Quantidade de pontos lidos:\", len(data))\n","print(\"Formato dos dados:\", data.shape)\n","print(\"\\nExemplos de dados:\", *[(x, y) for x,y in data[:5]], sep='\\n')"]},{"cell_type":"markdown","metadata":{"id":"qF4QzpSw4qZk"},"source":["A equipe deve aproveitar o algoritmo construído na Parte 1 e executar 10 repetições do mesmo para as seguintes configurações: η × I = {0.4, 0.1, 0.01} × {(−100, + 100), (−0.5, + 0.5)} em que I é o intervalo a ser utilizado para a distribuição uniforme do valor dos pesos. Assim, há 6 configurações a serem testadas, cada uma delas por 10 repetições."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17868,"status":"ok","timestamp":1716492061737,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"ch4Vy-6Y4qZk","outputId":"82daa29e-4127-41fc-b138-b6c620011365"},"outputs":[],"source":["perceptron = Perceptron(data)\n","rates = [0.4, 0.1, 0.01]\n","bounds = [100, 0.5]\n","\n","results = train_with_parameters(perceptron, rates, bounds)"]},{"cell_type":"markdown","metadata":{"id":"nzbKt1jC4qZk"},"source":["Para cada configuração, deve-se apresentar um único gráfico contendo as entradas e a solução obtida, para mostrar que todas as configurações, ainda que distintas, levam à convergência. O gráfico a ser mostrado pode conter a reta resultante da última repetição, por exemplo. É importante respeitar as sugestões de ilustração indicadas anteriormente."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2075,"status":"ok","timestamp":1716492063810,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"0PZYCJZo4qZl","outputId":"ea0457f4-64a5-4f5e-ff11-fc203daf8d50"},"outputs":[],"source":["table = PrettyTable()\n","table.field_names = [\n","    \"Taxa de Aprendizado\",\n","    \"Intervalo de Pesos\",\n","    \"Quantidade de Ajustes\",\n","    \"Menor número de épocas para convergência\",\n","]\n","\n","fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n","for ax, result in zip(axes.flat, results.items()):\n","    params, data = result\n","    learning_rate, bounds = params\n","\n","    last_weight = data[-1][\"final_weights\"]\n","\n","    mean_updates = np.mean([result[\"update_count\"] for result in data])\n","    std_updates = np.std([result[\"update_count\"] for result in data])\n","    min_epochs = np.min([result[\"epoch_count\"] for result in data])\n","\n","    table.add_row(\n","        [\n","            learning_rate,\n","            f\"({-bounds:.1f}, {bounds:.1f})\",\n","            f\"{mean_updates:.1f} ± {std_updates:.1f}\",\n","            min_epochs,\n","        ]\n","    )\n","\n","    plot_results(perceptron.input_data, perceptron.output_data, last_weight, ax)\n","    ax.set_title(f\"{learning_rate} × ({-bounds:.1f}, {bounds:.1f})\")\n","\n","fig.suptitle(\"Comparação de resultados: η × I \")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"w-9Xo61L4qZl"},"source":["Para cada configuração em suas 10 execuções, obter a média e o desvio padrão da quantidade de ajustes efetuados no vetor de pesos e o menor número de épocas até a convergência nestas 10 iterações. Dispor tais resultados sobre a forma de uma tabela e discutir se há uma configuração melhor ou pior que as demais ou se elas são equivalentes. Uma estrutura para esta tabela é sugerida a seguir, a qual foi preenchida com dados fictícios. Recomenda-se a utilização do pacote prettytable no notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716492063811,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"NJYKgAeL4qZl","outputId":"48582213-ffc3-45ac-ef43-fd300eef2cfd"},"outputs":[],"source":["table"]},{"cell_type":"markdown","metadata":{"id":"b6RYsdn54qZl"},"source":["# Parte 3 - Validação Holdout em Problema Não-Linearmente Separável\n","\n","Todas as equipes devem considerar o arquivo dataHoldout.txt e apresentar um gráfico inicial que\n","evidencie que este problema não é linearmente separável."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":986},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1716492064603,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"bNCNENfE4qZl","outputId":"84dbfb52-1d27-4b35-c6b1-f64bd6ac3f24"},"outputs":[],"source":["data = read_data(\"Holdout\")\n","\n","print(\"Quantidade de pontos lidos: \", len(data))\n","print(\"Formato dos dados: \", data.shape)\n","print(\"\\nExemplos de dados: \", *[(x, y) for x, y in data[:5]], sep=\"\\n\", end=\"\\n\\n\")\n","\n","auxiliary = Perceptron(data)\n","\n","fig, ax = plt.subplots(figsize=(8, 8))\n","plot_results(auxiliary.input_data, auxiliary.output_data, ax=ax)\n","ax.set_title(\"Problema não linearmente separável\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kffqGbSF4qZm"},"source":["Em seguida, os exemplos devem ser aleatoriamente divididos em duas partições, uma delas contendo 70% dos exemplos (treinamento) e outra contendo 30% (teste)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716492064603,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"FMm_8G5u4qZm","outputId":"d1209b5c-49e3-4b62-b9f0-21b37f5cc47a"},"outputs":[],"source":["train_data, test_data = train_test_split(data)\n","print(\"Quantidade de pontos para treinamento: \", len(train_data))\n","print(\"Quantidade de pontos para teste: \", len(test_data))"]},{"cell_type":"markdown","metadata":{"id":"ciKW9yqj4qZm"},"source":["Embora o problema não seja linearmente separável, vamos utilizar os dados de treinamento para obter uma reta de separação das classes com o neurônio Perceptron (solução possível). O neurônio em questão tem função de ativação degrau com ϑ = 0, os valores de η e de inicialização de pesos devem seguir as recomendações da literatura e os pesos do neurônio devem ser aleatoriamente escolhidos a partir de U (−0,5,+0,5)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716492064603,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"HURTpvSh4qZm","outputId":"ec6509c4-cc3a-4cec-ff25-3b587d49583c"},"outputs":[],"source":["perceptron = Perceptron(train_data)\n","perceptron.randomize_weights(floor=-0.5, ceiling=0.501)\n","print(\"Vetor de pesos após a randomização: \", perceptron.weights)"]},{"cell_type":"markdown","metadata":{"id":"g3uVn7724qZm"},"source":["Execute o algoritmo por 100 épocas, mas a cada época apresente os exemplos disponíveis com conjunto de treinamento em ordem aleatória."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1716492065135,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"Zoke_vNX4qZn","outputId":"1e69c968-f7b6-4091-90e4-4fbd25968e0f"},"outputs":[],"source":["epoch, updates = perceptron.shuffle_train(100)\n","\n","print(\"\\nTreinamento finalizado!\")\n","print(\"Quantidade de épocas treinadas: \", epoch)\n","print(\"Quantidade de ajustes no vetor de pesos: \", updates)\n","print(\"Quantidade de ajustes em cada época: \", perceptron.updates_per_epoch)"]},{"cell_type":"markdown","metadata":{"id":"ecg1oDtu4qZn"},"source":["Efetue a previsão da saída deste neurônio para todos os exemplos do conjunto de teste, comparando-a com a saída desejada e responda ao que se pede:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":428,"status":"ok","timestamp":1716492266192,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"GN1uxJAR4qZn"},"outputs":[],"source":["auxiliary.data = test_data\n","\n","predictions_test = []\n","for test in auxiliary._input_data:\n","    predictions_test.append(perceptron.predict(test))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716492267580,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"nTUZq_6C5zPq"},"outputs":[],"source":["predictions_train = []\n","for train in perceptron._input_data:\n","    predictions_train.append(perceptron.predict(train))"]},{"cell_type":"markdown","metadata":{"id":"qS9pgpYy4qZn"},"source":["1. Apresente a matriz de confusão das previsões efetuadas para o conjunto de testes;"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716492065135,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"VCP_cZaL4qZn"},"outputs":[],"source":["draw_matrix(auxiliary._output_data,predictions_test)"]},{"cell_type":"markdown","metadata":{"id":"Bh9P1w2F4qZn"},"source":["2. Qual a acurácia da solução proposta para os dados do conjunto de treinamento inicialmente fornecido?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1716492269885,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"LFasTYDv4qZn","outputId":"15058be0-cc8a-48e0-c633-e475225f0704"},"outputs":[],"source":["accuracy = accuracy_score(perceptron._output_data, predictions_train)\n","\n","print(\"Acurácia no conjunto de treinamento:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"9sWprkU24qZo"},"source":["3. Nos mesmos termos da questão anterior, obtenha os valores de precisão, revocação e F-Score Para estes cálculos, está liberada a utilização de sklearn.metrics;"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1716492290552,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"Vw0YigsA4qZo","outputId":"83d5de99-571d-4643-9cce-2df60aa0fb81"},"outputs":[],"source":["f1 = f1_score(perceptron._output_data, predictions_train)\n","recall = recall_score(perceptron._output_data, predictions_train)\n","precision = precision_score(perceptron._output_data, predictions_train)\n","\n","print(\"F1-Score no conjunto de treinamento:\", f1)\n","print(\"Revocação no conjunto de treinamento:\", recall)\n","print(\"Precisão no conjunto de treinamento:\", precision)"]},{"cell_type":"markdown","metadata":{"id":"RukGixtf4qZo"},"source":["4. A partir destas métricas, discorra acerca da qualidade desta solução perante o conjunto de testes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1716492294874,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"YQ3I42Oj4qZo","outputId":"e1590132-5ea1-414f-aebb-7b0201bcc9e8"},"outputs":[],"source":["accuracy = accuracy_score(auxiliary._output_data, predictions_test)\n","f1 = f1_score(auxiliary._output_data, predictions_test)\n","recall = recall_score(auxiliary._output_data, predictions_test)\n","precision = precision_score(auxiliary._output_data, predictions_test)\n","\n","print(\"Acurácia:\", accuracy)\n","print(\"F1-Score:\", f1)\n","print(\"Revocação:\", recall)\n","print(\"Precisão:\", precision)"]},{"cell_type":"markdown","metadata":{"id":"yKAyG2Pe4qZp"},"source":["Apresente dois gráficos com a solução obtida pelo neurônio Perceptron, mas um deles contendo os dados de treinamento e o outro contendo os dados de teste. Disponha tais gráficos lado a lado."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1716492065136,"user":{"displayName":"Felipe Muniz Amorim","userId":"04623857256439303007"},"user_tz":240},"id":"M4UbdVAw4qZq"},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n","ax_train, ax_test = axes\n","\n","plot_results(\n","    perceptron.input_data, perceptron.output_data, perceptron.weights, ax=ax_train\n",")\n","ax_train.set_title(\"Dados de treinamento\")\n","\n","plot_results(\n","    auxiliary.input_data, auxiliary.output_data, perceptron.weights, ax=ax_test\n",")\n","ax_test.set_title(\"Dados de teste\")\n","\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["ul4fYqLR4qZW","BDwus15u4qZX","xQIo_qGU4qZh"],"provenance":[]},"kernelspec":{"display_name":"rna_perceptron","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
